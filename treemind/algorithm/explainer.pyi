import pandas as pd
from numpy.typing import ArrayLike
import numpy as np
from typing import Union, Tuple, List, Any

class Explainer:
    """
    The Explainer class provides methods to analyze and interpret a trained model by examining
    feature dependencies, split points, interaction effects, and predicted values. This class
    enables detailed inspection of how individual features and their interactions impact model
    predictions, allowing for a clearer understanding of the model's decision-making process.
    """

    def analyze_interaction(self, main_col: int, sub_col: int) -> pd.DataFrame:
        """
        Analyzes the interaction between two features.

        Parameters
        ----------
        main_col : int
            The column index of the main feature to analyze.

        sub_col : int
            The column index of the sub feature with which to analyze the dependency.

        Returns
        -------
        pd.DataFrame
            A DataFrame containing the following columns:

            - `main_feature_lb`: Lower bound for the main feature interval (automatically named by the model).

            - `main_feature_ub`: Upper bound for the main feature interval (automatically named by the model, inclusive).

            - `sub_feature_lb`: Lower bound for the sub feature interval.

            - `sub_feature_ub`: Upper bound for the sub feature interval, inclusive.

            - `value`: A value indicating the interaction effect or dependency strength between the main and sub features within the specified interval combination.

        Notes
        -----
        - The naming of the `main_feature_lb`, `main_feature_ub`, `sub_feature_lb`, and `sub_feature_ub` columns is model-determined. If the column names are unspecified during training, they are auto-assigned based on indices.

        - Each row in the output DataFrame represents a unique combination of intervals between the main and sub features, showing the value associated with the interaction within these intervals.
        """
        ...

    def __call__(self, model: Any) -> None:
        """
        Invokes the Explainer instance with a model to perform analysis.

        Parameters
        ----------
        model : Any
            A trained model instance.

        Returns
        -------
        None
        """
        ...

    def analyze_data(
        self, x: ArrayLike, back_data: ArrayLike | None = None
    ) -> np.ndarray:
        """
        Analyzes input data to extract row and column-based impact values, with an option to use
        baseline data for feature impact calculation.

        Parameters
        ----------
        x : ArrayLike
            Input data for analysis. The data type of `x` should be compatible with the trained model,
            which can accept any type that matches its input requirements. Note that `x` must be
            two-dimensional; single-dimensional arrays are not accepted. If input is intended to
            be row-based, it must have the appropriate shape.
            
        back_data : ArrayLike, optional
            Baseline data used to calculate impact values. When provided, each feature's effect is
            computed as the deviation from this baseline value, similar to SHAP analysis. If `None`, 
            the function will use the modelâ€™s expected output as the reference for impact calculations.

        Returns
        -------
        np.ndarray
            A two-dimensional array where each element represents the impact of a feature in `x` on a
            specific row, based on either the provided baseline (`back_data`) or the model's output 
            as the reference if `back_data` is `None`. The array shape corresponds to (n_rows, n_features), 
            where each row gives the per-feature impact for a specific instance in `x`, enabling row 
            and column-based impact analysis.
            
        """
        ...


    def analyze_feature(self, col: int) -> pd.DataFrame:
        """
        Analyzes a specific feature by calculating the mean, min, and max values
        based on split points across trees for the given column, with upper bounds inclusive.

        Parameters
        ----------
        col : int
            The column index of the feature to analyze.

        Returns
        -------
        pd.DataFrame
            A DataFrame containing the following columns:
            - `feature_lb`: Lower bound of the interval for the feature (automatically named by the model).
            - `feature_ub`: Upper bound of the interval for the feature (automatically named by the model, inclusive).
            - `mean`: Average of the data points within the interval according to the model.
            - `min`: Minimum value that data can take in this interval.
            - `max`: Maximum value that data can take in this interval.

        Notes
        -----
        The names of `feature_lb` and `feature_ub` columns are generated by the model and cannot be manually adjusted.
        If no column names are specified during the training phase, they are automatically indexed by the model.
        """
        ...

    def count_node(self, interaction: bool = True) -> pd.DataFrame:
        """
        Counts how often features (or pairs of features if interaction is True) appear in decision splits across the model's trees.

        Parameters
        ----------
        interaction : bool, default True
            If True, counts how often pairs of features appear together in splits.
            If False, counts how often individual features appear in splits.

        Returns
        -------
        pd.DataFrame
            The output depends on the `interaction` parameter:

            - If `interaction` is True:
                The function returns a DataFrame with the following columns:

                - `column1_index` (int): Index of the first feature.

                - `column2_index` (int): Index of the second feature.

                - `count` (int): Number of times the feature pair appears together in splits.

            - If `interaction` is False:
                The function returns a DataFrame with the following columns:

                - `column_index` (int): Index of the feature.

                - `count` (int): Number of times the feature appears in splits.
        """
        ...
